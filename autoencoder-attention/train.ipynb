{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1751160151358,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "wXEXB5OPG-y6"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    block_size: int = 64\n",
    "    vocab_size: int = 65\n",
    "    n_channel : int = 16\n",
    "    n_embd    : int = 16\n",
    "    n_layer   : int = 3\n",
    "    n_head    : int = 8\n",
    "    batch_size: int = 32\n",
    "\n",
    "    device        : str   = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    learning_rate : int   = 3e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1751160151395,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "q68rqErgHLE5"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, red= 4):\n",
    "        super().__init__()\n",
    "        self.activation = nn.GELU(approximate='tanh')\n",
    "        self.fc_in      = nn.Linear(dim, dim // red, bias= False)\n",
    "        self.fc_hidden  = nn.Linear(dim // red, dim // red, bias= False)\n",
    "        self.fc_out     = nn.Linear(dim // red, dim, bias= False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      # Encoder\n",
    "      encoded = self.activation(self.fc_in(x))\n",
    "      encoded = self.activation(self.fc_hidden(encoded))\n",
    "\n",
    "      # Decoder\n",
    "      decoded = self.fc_out(encoded)\n",
    "      return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1751160151396,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "xTbf6OoqJBOJ"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.key    = AutoEncoder(config.n_embd) # key   matrix\n",
    "        self.query  = AutoEncoder(config.n_embd) # query matrix\n",
    "        self.value  = AutoEncoder(config.n_embd) # value matrix\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size,config.block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        _,t,_ = x.shape # to mask incase if the sequence changes\n",
    "\n",
    "        k = self.key(x)   # batch wise matrix multiplication\n",
    "        q = self.query(x) # batch wise matrix multiplication\n",
    "        v = self.value(x) # batch wise matrix multiplication\n",
    "\n",
    "        scores = q @ k.transpose(-2, -1) # dot product to get attn scores\n",
    "        scores = scores * (1.0 / math.sqrt(k.size(-1))) # scaled down\n",
    "\n",
    "        mask = self.tril[:t, :t]                              # causal mask (B, T, T)\n",
    "        scores = scores.masked_fill(mask == 0, float(\"-inf\")) # mask scores\n",
    "        scores = F.softmax(scores, dim=-1)                    # softmax normalize\n",
    "        out  = scores @ v                                     # attention matrix multiplication\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1751160151397,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "c8Tfi7xjLYMQ"
   },
   "outputs": [],
   "source": [
    "class AETransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = Head(config)                # auto encoder attention head\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd) # layer normalization\n",
    "\n",
    "        self.w_emb = nn.Embedding(config.vocab_size, config.n_embd)             # token embedding\n",
    "        self.p_emb = nn.Embedding(config.block_size, config.n_embd)             # position embedding\n",
    "\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)  # output layer\n",
    "        self.to(config.device)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        _,t = idx.shape # time dimesnion length for optimisation and positoin\n",
    "\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=idx.device)\n",
    "        out = self.w_emb(idx) + self.p_emb(pos) # pos + embedding\n",
    "\n",
    "        out = out + self.head(self.ln_1(out))  #add (residual connection) + layer norm + mimicked attentioon\n",
    "        logits = self.lm_head(out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "          B,T,C     = logits.shape\n",
    "          logits    = logits.view(B*T, C)\n",
    "          targets = targets.view(B*T)\n",
    "\n",
    "          loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens,block_size):\n",
    "\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "          idx_cond = idx[:, -block_size:]\n",
    "\n",
    "          logits , _ = self(idx)\n",
    "\n",
    "          logits = logits[:, -1, :] # becomes (B, C)\n",
    "\n",
    "          probs = F.softmax(logits, dim=-1)\n",
    "          idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "          idx = torch.cat((idx, idx_next), dim=1) # (B, T+1z)\n",
    "        return idx.squeeze().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1751160151397,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "Na1zMBikOBMg"
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "mT = AETransformer(config=config)\n",
    "optimizer = torch.optim.AdamW(mT.parameters(), lr=config.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1751160151527,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "rh55GIz7P3Ry",
    "outputId": "2fabb108-ec04-4d2a-e533-59c8e8eadc43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-29 01:22:31--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.5’\n",
      "\n",
      "\rinput.txt.5           0%[                    ]       0  --.-KB/s               \rinput.txt.5         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-06-29 01:22:31 (21.5 MB/s) - ‘input.txt.5’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1751160151530,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "zOC65ZMdPkyQ"
   },
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1751160151762,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "U40aasp7Pqpg",
    "outputId": "2d4d7930-dcc3-4170-a10b-58f3ef405bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = 65\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(len(data))\n",
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751160151762,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "igx1kuZNPQp_"
   },
   "outputs": [],
   "source": [
    "def get_batch(split, config):\n",
    "    block_size = config.block_size\n",
    "    batch_size = config.batch_size\n",
    "    device = config.device\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device=device), y.to(device=device)\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67107,
     "status": "ok",
     "timestamp": 1751160218867,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "AhrwLTV1OEG0",
    "outputId": "500c5f31-1dc7-4db8-c86f-ed82c0f27175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 4.4705\n",
      "Sample: Ogx!qgfsviDvI.&Rg,w-naK'Khyf3.WHQm,MB! \n",
      "lIVrKNyRdWW'r!CXRWWjBIRg:\n",
      "Epoch: 500 | Loss: 2.3885\n",
      "Sample: ncen illenere te\n",
      "duregied-ld-?\n",
      "HARCLOLLUES:\n",
      "To nge theee yorenere\n",
      "Epoch: 1000 | Loss: 2.3629\n",
      "Sample: ; wer:\n",
      "Nad worealobe yound leind Orofe fot, nory onthexthe woowth\n",
      "Epoch: 1500 | Loss: 2.3333\n",
      "Sample: bis: bich dibys mukle, alif thany, thomid itstive thig, thanth yo\n",
      "Epoch: 2000 | Loss: 2.3587\n",
      "Sample: Y:\n",
      "On ton, I Ooth ath thind; wa we foo.\n",
      "Whoeny ghat mys aligrkis \n",
      "Epoch: 2500 | Loss: 2.3835\n",
      "Sample: 3:\n",
      "\n",
      "\n",
      "Whe de he's aduny,\n",
      "The keand sos ard drovequge, byond zes to\n",
      "Epoch: 3000 | Loss: 2.3471\n",
      "Sample: SODUSBUSAR:\n",
      "Haspr'd llet, fase pralolll wis, ye. Bar.\n",
      "\n",
      "IOLEO:\n",
      "Bu \n",
      "Epoch: 3500 | Loss: 2.3441\n",
      "Sample: QULI:\n",
      "Wice me hang thingh doth\n",
      "Fink Rou, my beinth vakes.\n",
      "\n",
      "GIUCAN\n",
      "Epoch: 4000 | Loss: 2.2731\n",
      "Sample: VI her hin me no me the, y, cout porsthar ood ur tow's tontheant \n",
      "Epoch: 4500 | Loss: 2.2413\n",
      "Sample: :\n",
      "Fad! hon anow fry  as, ianf ay et; ankey ainth weap\n",
      "USTIUS:\n",
      "Wel\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(5000):\n",
    "\n",
    "    x, y  = get_batch('train', config)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()           # clear old gradients\n",
    "    _, loss = mT(x, y)              # forward pass\n",
    "    loss.backward()                 # back-propagate\n",
    "    optimizer.step()                # update weights\n",
    "\n",
    "    if epochs % 500 == 0:\n",
    "        context = torch.randint(high=len(chars), size=(1, 1))\n",
    "        print(f\"Epoch: {epochs} | Loss: {loss.item():.4f}\")\n",
    "        generated_text = decode(mT.generate(context, config.block_size, config.block_size))\n",
    "        print(f\"Sample: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1751160218877,
     "user": {
      "displayName": "chukwudi donald",
      "userId": "04653286918829027864"
     },
     "user_tz": 240
    },
    "id": "sQIHDSeIQDwe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMF5KlepvGg1/tVY0h49Imh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
